{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Subset higher order stats by our bounding boxes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#A list of imports we need for code later in the notebook.\n",
      "#The css_styles() function must go last.\n",
      "%matplotlib inline\n",
      "from owslib.wfs import WebFeatureService\n",
      "import json\n",
      "from utilities import find_dict_keys\n",
      "from shapely.geometry import shape, MultiPolygon\n",
      "from shapely.geometry import box\n",
      "\n",
      "import folium\n",
      "from utilities import get_coords\n",
      "from IPython.core.display import HTML\n",
      "\n",
      "import time\n",
      "import numpy as np\n",
      "from numpy import ma\n",
      "import netCDF4\n",
      "import pandas as pd\n",
      "from pandas import Series\n",
      "\n",
      "import matplotlib as mpl\n",
      "from matplotlib import cm\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib import ticker\n",
      "\n",
      "from utilities import css_styles\n",
      "css_styles()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <style>\n",
        "        .info {\n",
        "            background-color: #fcf8e3; border-color: #faebcc; border-left: 5px solid #8a6d3b; padding: 0.5em; color: #8a6d3b;\n",
        "        }\n",
        "        .success {\n",
        "            background-color: #d9edf7; border-color: #bce8f1; border-left: 5px solid #31708f; padding: 0.5em; color: #31708f;\n",
        "        }\n",
        "        .error {\n",
        "            background-color: #f2dede; border-color: #ebccd1; border-left: 5px solid #a94442; padding: 0.5em; color: #a94442;\n",
        "        }\n",
        "        .warning {\n",
        "            background-color: #fcf8e3; border-color: #faebcc; border-left: 5px solid #8a6d3b; padding: 0.5em; color: #8a6d3b;\n",
        "        }\n",
        "        </style>\n",
        "    "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x7f9597791c90>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load our important bird areas again.\n",
      "known_wfs = \"http://solo.axiomalaska.com/geoserver/audubon_ibav3/ows\"\n",
      "wfs = WebFeatureService(known_wfs, version='1.0.0')\n",
      "geojson_response = wfs.getfeature(typename=['audubon_ibav3:audubon_ibas_v3_20aug2014'], outputFormat=\"application/json\", srsname=\"urn:x-ogc:def:crs:EPSG:4326\").read()\n",
      "geojson = json.loads(geojson_response)\n",
      "\n",
      "geometries = find_dict_keys('geometry', geojson)\n",
      "shapes = [shape(g) for g in geometries]\n",
      "\n",
      "ids = find_dict_keys('id', geojson)\n",
      "ids=[str(j) for j in ids]\n",
      "\n",
      "sitenums = find_dict_keys('newsitenam', geojson)\n",
      "sitenums = [str(s) for s in sitenums]\n",
      "nsites=len(sitenums)\n",
      "\n",
      "#This generates bounding boxes from the complex geometries in shapes.\n",
      "minlat = list()\n",
      "minlon = list()\n",
      "maxlat = list()\n",
      "maxlon = list()\n",
      "for s in shapes:\n",
      "    minlat.append(s.bounds[0])\n",
      "    minlon.append(s.bounds[1])\n",
      "    maxlat.append(s.bounds[2])\n",
      "    maxlon.append(s.bounds[3])\n",
      "# miny, minx, maxy, maxx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Longitudes in the model are in positive east.\n",
      "#Longitudes in the shape files are -180/180, which I'll convert to the model coordinates\n",
      "\n",
      "for x in range(nsites):\n",
      "    if minlon[x] < 0:\n",
      "        minlon[x] = minlon[x]+360.\n",
      "    if maxlon[x] < 0:\n",
      "        maxlon[x] = maxlon[x]+360."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Bring in netCDF datasets\n",
      "#Set datasets\n",
      "avg = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/Outputs/core_average.nc')\n",
      "stddev = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/Outputs/core_rmssdn.nc')\n",
      "pavg = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/Outputs/cccma_average.nc')\n",
      "pstddev = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/Outputs/cccma_rmssdn.nc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load latitude and longitude arrays\n",
      "latitude = np.array(avg.variables['LATITUDE'])\n",
      "longitude = np.array(avg.variables['LONGITUDE'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up depth bins, for these data, they are in meters\n",
      "\n",
      "depthbins = pd.DataFrame({'mindepth': [0, 10, 75],\n",
      "                          'maxdepth': [5, 60, 200]},\n",
      "                         index=['surface', 'midwater','deepwater'],\n",
      "                         columns=['mindepth', 'maxdepth', 'minz', 'maxz'])\n",
      "\n",
      "depth = np.array(avg.variables['zsalt'])\n",
      "depthindices=list()\n",
      "for d in range(len(depthbins.index)):\n",
      "    indicesz=np.where(np.logical_and(depth[:] <= depthbins.maxdepth[d],\n",
      "                                     depth[:] >= depthbins.mindepth[d]))\n",
      "    depthindices.append(indicesz[0])\n",
      "    if len(depthindices[d]) > 0:\n",
      "        depthbins.minz[d] = min(depthindices[d])\n",
      "        depthbins.maxz[d] = max(depthindices[d])\n",
      "        \n",
      "depthbins['label']=['0 to 5 m', '10 to 60 m', '75 to 200 m']\n",
      "        \n",
      "depthbins"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>mindepth</th>\n",
        "      <th>maxdepth</th>\n",
        "      <th>minz</th>\n",
        "      <th>maxz</th>\n",
        "      <th>label</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>surface</th>\n",
        "      <td>  0</td>\n",
        "      <td>   5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "      <td>    0 to 5 m</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>midwater</th>\n",
        "      <td> 10</td>\n",
        "      <td>  60</td>\n",
        "      <td> 2</td>\n",
        "      <td>  8</td>\n",
        "      <td>  10 to 60 m</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>deepwater</th>\n",
        "      <td> 75</td>\n",
        "      <td> 200</td>\n",
        "      <td> 9</td>\n",
        "      <td> 13</td>\n",
        "      <td> 75 to 200 m</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "           mindepth  maxdepth minz maxz        label\n",
        "surface           0         5    0    1     0 to 5 m\n",
        "midwater         10        60    2    8   10 to 60 m\n",
        "deepwater        75       200    9   13  75 to 200 m"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But each of these also need four slots for the [avg, stddev, pavg, pstddev]. I think it's best to create a new dataframe for each variable, test for depth, and if it has depth create the bins and add the columns to the individual dataframe. At the end, we can add all the dataframes together for output via a CSV.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This is our known metadata for the outputs\n",
      "metadata = pd.DataFrame({\n",
      "         'orgName': [\n",
      "                   #these don't have depth\n",
      "                   'icephl_latlon','ben_latlon',\n",
      "                   'aice_latlon',\n",
      "                   #these do\n",
      "                 'phs_latlon','phl_latlon','mzl_latlon','cop_latlon','ncao_latlon','ncas_latlon','eup_latlon','det_latlon',\n",
      "                 'temp_latlon',\n",
      "                 'u_latlon',\n",
      "                 'v_latlon',],\n",
      "         'name': ['Ice Phytoplankton Concentration',\n",
      "                  'Benthos Concentration',\n",
      "                  'Sea Ice Area Fraction',\n",
      "                  'Small Phytoplankton Concentration',\n",
      "                  'Large Phytoplankton Concentration',\n",
      "                  'Large Microzooplankton Concentration',\n",
      "                  'Small Coastal Copepod Concentration',\n",
      "                  'Offshore Neocalanus Concentration',\n",
      "                  'Neocalanus Concentration',\n",
      "                  'Euphausiids Concentration',\n",
      "                  'Detritus Concentration',\n",
      "                  'Sea Water Temperature',\n",
      "                  'Zonal (U) Current',\n",
      "                  'Meridional (V) Current'],\n",
      "         'units': ['mgC/m2','mgC/m2',\n",
      "                   'Fraction',\n",
      "                   'mgC/m3','mgC/m3','mgC/m3','mgC/m3','mgC/m3','mgC/m3','mgC/m3','mgC/m3',\n",
      "                   'degrees C',\n",
      "                   'm/s',\n",
      "                   'm/s']\n",
      "       })"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>orgName</th>\n",
        "      <th>units</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>   Ice Phytoplankton Concentration</td>\n",
        "      <td> icephl_latlon</td>\n",
        "      <td>   mgC/m2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>             Benthos Concentration</td>\n",
        "      <td>    ben_latlon</td>\n",
        "      <td>   mgC/m2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>             Sea Ice Area Fraction</td>\n",
        "      <td>   aice_latlon</td>\n",
        "      <td> Fraction</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Small Phytoplankton Concentration</td>\n",
        "      <td>    phs_latlon</td>\n",
        "      <td>   mgC/m3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Large Phytoplankton Concentration</td>\n",
        "      <td>    phl_latlon</td>\n",
        "      <td>   mgC/m3</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "                                name        orgName     units\n",
        "0    Ice Phytoplankton Concentration  icephl_latlon    mgC/m2\n",
        "1              Benthos Concentration     ben_latlon    mgC/m2\n",
        "2              Sea Ice Area Fraction    aice_latlon  Fraction\n",
        "3  Small Phytoplankton Concentration     phs_latlon    mgC/m3\n",
        "4  Large Phytoplankton Concentration     phl_latlon    mgC/m3"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some shapes will be empty (i.e., there's a polygon, but no model data), others will have very few values. We should keep track of how many model pixels are going into each resulting mean. For the combined IBAs, there are 210 polygons, identified by sitenums, objectids, and their geometries.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Store the results by keeping track of the data in a Panda Dataframes\n",
      "We will append columns to these and fill in the data as we get it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nsites"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "207\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create a dataframe to house the IBA site information, indexed by the IBA sitenums.\n",
      "siteinfo = pd.DataFrame(\n",
      "                        {\n",
      "                        'id':ids,\n",
      "                        'minlat': minlat,\n",
      "                        'minlon': minlon,\n",
      "                        'maxlat': maxlat,\n",
      "                        'maxlon': maxlon,\n",
      "                        'tested': (['no'] * nsites)\n",
      "                        },\n",
      "                        index = sitenums\n",
      "                       )\n",
      "\n",
      "#We'll also add one more row, for the whole area, as a reference\n",
      "areainfo = pd.DataFrame(\n",
      "                        {\n",
      "                        'id': 'None',\n",
      "                        'minlat': min(latitude),\n",
      "                        'minlon': min(longitude),\n",
      "                        'maxlat': max(latitude),\n",
      "                        'maxlon': max(longitude),\n",
      "                        'miny': [0],\n",
      "                        'minx': [0],\n",
      "                        'maxy': [len(latitude)],\n",
      "                        'maxx': [len(longitude)],\n",
      "                        'tested': ['yes']\n",
      "                        },\n",
      "                        index = ['Whole Area']\n",
      "                       )\n",
      "\n",
      "siteinfo=siteinfo.append(areainfo)\n",
      "siteinfo=siteinfo[['id', 'minlat', 'maxlat', 'minlon', 'maxlon', 'miny', 'maxy', 'minx', 'maxx', 'tested']]\n",
      "nsites=nsites+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "siteinfo.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>minlat</th>\n",
        "      <th>maxlat</th>\n",
        "      <th>minlon</th>\n",
        "      <th>maxlon</th>\n",
        "      <th>miny</th>\n",
        "      <th>maxy</th>\n",
        "      <th>minx</th>\n",
        "      <th>maxx</th>\n",
        "      <th>tested</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Kasegaluk Lagoon</th>\n",
        "      <td> audubon_ibas_v3_20aug2014.201</td>\n",
        "      <td> 69.230020</td>\n",
        "      <td> 70.609741</td>\n",
        "      <td> 196.583407</td>\n",
        "      <td> 200.102151</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Alitak Bay</th>\n",
        "      <td> audubon_ibas_v3_20aug2014.202</td>\n",
        "      <td> 56.502518</td>\n",
        "      <td> 57.038473</td>\n",
        "      <td> 205.640254</td>\n",
        "      <td> 206.239318</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Kuskokwim River Delta</th>\n",
        "      <td> audubon_ibas_v3_20aug2014.203</td>\n",
        "      <td> 59.794117</td>\n",
        "      <td> 60.812786</td>\n",
        "      <td> 194.579424</td>\n",
        "      <td> 197.655033</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Northeast Arctic Coastal Plain</th>\n",
        "      <td> audubon_ibas_v3_20aug2014.207</td>\n",
        "      <td> 69.774886</td>\n",
        "      <td> 70.100611</td>\n",
        "      <td> 213.684784</td>\n",
        "      <td> 215.335517</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Whole Area</th>\n",
        "      <td>                          None</td>\n",
        "      <td> 50.000000</td>\n",
        "      <td> 66.000000</td>\n",
        "      <td> 160.000000</td>\n",
        "      <td> 210.000000</td>\n",
        "      <td>  0</td>\n",
        "      <td> 161</td>\n",
        "      <td>  0</td>\n",
        "      <td> 251</td>\n",
        "      <td> yes</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "                                                           id     minlat  \\\n",
        "Kasegaluk Lagoon                audubon_ibas_v3_20aug2014.201  69.230020   \n",
        "Alitak Bay                      audubon_ibas_v3_20aug2014.202  56.502518   \n",
        "Kuskokwim River Delta           audubon_ibas_v3_20aug2014.203  59.794117   \n",
        "Northeast Arctic Coastal Plain  audubon_ibas_v3_20aug2014.207  69.774886   \n",
        "Whole Area                                               None  50.000000   \n",
        "\n",
        "                                   maxlat      minlon      maxlon  miny  maxy  \\\n",
        "Kasegaluk Lagoon                70.609741  196.583407  200.102151   NaN   NaN   \n",
        "Alitak Bay                      57.038473  205.640254  206.239318   NaN   NaN   \n",
        "Kuskokwim River Delta           60.812786  194.579424  197.655033   NaN   NaN   \n",
        "Northeast Arctic Coastal Plain  70.100611  213.684784  215.335517   NaN   NaN   \n",
        "Whole Area                      66.000000  160.000000  210.000000     0   161   \n",
        "\n",
        "                                minx  maxx tested  \n",
        "Kasegaluk Lagoon                 NaN   NaN     no  \n",
        "Alitak Bay                       NaN   NaN     no  \n",
        "Kuskokwim River Delta            NaN   NaN     no  \n",
        "Northeast Arctic Coastal Plain   NaN   NaN     no  \n",
        "Whole Area                         0   251    yes  "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now convert the latlons to pixel indices for the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latindices = list()\n",
      "lonindices = list()\n",
      "\n",
      "for x in range(nsites):\n",
      "    #first do latitude\n",
      "    indicesy = np.where(np.logical_and(latitude <= siteinfo.maxlat[x],\n",
      "                                       latitude >= siteinfo.minlat[x]))\n",
      "    latindices.append(indicesy[0])\n",
      "    #then longitude\n",
      "    #PMEL models are in positive east, so we have to convert our bounding box.\n",
      "    indicesx = np.where(np.logical_and(longitude[:] <= siteinfo.maxlon[x],\n",
      "                                       longitude[:] >= siteinfo.minlon[x]))\n",
      "    lonindices.append(indicesx[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#finds the minimum and maxium pixel indices for each sitenum\n",
      "avgdata = ma.masked_array(avg.variables[metadata.orgName[0]][:])\n",
      "for x in range(nsites-1):\n",
      "    if len(latindices[x]) > 0:\n",
      "        siteinfo.miny[x] = min(latindices[x])\n",
      "        siteinfo.maxy[x] = max(latindices[x])\n",
      "    if len(lonindices[x]) > 0:\n",
      "        siteinfo.minx[x] = min(lonindices[x])\n",
      "        siteinfo.maxx[x] = max(lonindices[x]) \n",
      "#This tests to see if there are any NaNs, meaning the IBA goes off the edge of the model.\n",
      "#We'll skip any of those IBAs by setting a \"Tested\" variable to 0.\n",
      "    if pd.notnull(siteinfo.miny[x]):\n",
      "        if pd.notnull(siteinfo.maxy[x]):\n",
      "            if pd.notnull(siteinfo.minx[x]):\n",
      "                if pd.notnull(siteinfo.maxx[x]):\n",
      "                    #This will find if there are any non-masked values to test.\n",
      "                    count = ma.count(avgdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1])\n",
      "                    if count > 0:\n",
      "                        siteinfo.tested[x] = 'yes'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "siteinfo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Index: 208 entries, Jacksmith Bay to Cape Pierce to Whole Area\n",
        "Data columns (total 10 columns):\n",
        "id        208  non-null values\n",
        "minlat    208  non-null values\n",
        "maxlat    208  non-null values\n",
        "minlon    208  non-null values\n",
        "maxlon    208  non-null values\n",
        "miny      183  non-null values\n",
        "maxy      183  non-null values\n",
        "minx      164  non-null values\n",
        "maxx      164  non-null values\n",
        "tested    208  non-null values\n",
        "dtypes: float64(8), object(2)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 208 entries, Jacksmith Bay to Cape Pierce to Whole Area\n",
        "Data columns (total 10 columns):\n",
        "id        208  non-null values\n",
        "minlat    208  non-null values\n",
        "maxlat    208  non-null values\n",
        "minlon    208  non-null values\n",
        "maxlon    208  non-null values\n",
        "miny      183  non-null values\n",
        "maxy      183  non-null values\n",
        "minx      164  non-null values\n",
        "maxx      164  non-null values\n",
        "tested    208  non-null values\n",
        "dtypes: float64(8), object(2)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Process the data into a list of dataframes, indexed by sitenum"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have the pixel mins and maxes, we can iterate through the variables:\n",
      "\n",
      "1. Check for depth: if present iterate three times for depth bins, if absent, just do once.  \n",
      "2. Using the pixel indexes to subset each model variable for avg, stddev, pavg, and pstddev arrays and average those values.  \n",
      "3. Create a data frame with the mean avg, stddev, pavg, and pstddev for each sitenum, and append to list of dataframe results\n",
      "4. Create a label including the variable name and depth bin, append to another list of results. There should be one label for each dataframe.\n",
      "5. We'll concatenate these dataframes to the siteinfo dataframe into large dataframe for output to CSV."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nvariables = len(metadata.orgName)\n",
      "#create an empty dataframe\n",
      "dfresults = pd.DataFrame(index = siteinfo.index)\n",
      "\n",
      "#for each variable\n",
      "for i in range(nvariables): \n",
      "    #Load in the data\n",
      "    avgdata = ma.masked_array(avg.variables[metadata.orgName[i]][:])\n",
      "    mask=ma.getmask(avgdata)\n",
      "    stddevdata = ma.masked_array(stddev.variables[metadata.orgName[i]][:], mask)\n",
      "    pavgdata = ma.masked_array(pavg.variables[metadata.orgName[i]][:], mask)\n",
      "    pstddevdata = ma.masked_array(pstddev.variables[metadata.orgName[i]][:], mask)\n",
      "    \n",
      "    #check for depth\n",
      "    if len(avgdata.shape) == 3:\n",
      "        avgvals = list()\n",
      "        stddevvals = list()\n",
      "        pavgvals = list()\n",
      "        pstddevvals = list()\n",
      "        count = list()\n",
      "        \n",
      "        for x in range(nsites):\n",
      "            if (siteinfo.tested[x] == 'yes'):\n",
      "                #mean of data(latitude_indices, longitude_indices)\n",
      "                #The +1 is necessary because numpy indexing goes from start:end, but end is the first value that's NOT included.\n",
      "                #Whereas the way I've set this up, the maxy and maxx SHOULD be included.\n",
      "                avgvals.append(ma.mean(avgdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                stddevvals.append(ma.mean(stddevdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                pavgvals.append(ma.mean(pavgdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                pstddevvals.append(ma.mean(pstddevdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                count.append(ma.count(avgdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "\n",
      "            else:\n",
      "                avgvals.append(np.nan)\n",
      "                stddevvals.append(np.nan)\n",
      "                pavgvals.append(np.nan)\n",
      "                pstddevvals.append(np.nan)\n",
      "                count.append(np.nan)\n",
      "        \n",
      "        dfresults[metadata.name[i]+' Count'] = count\n",
      "        dfresults[metadata.name[i]+' Avg'] = avgvals\n",
      "        dfresults[metadata.name[i]+' StdDev'] = stddevvals\n",
      "        dfresults[metadata.name[i]+' PAvg'] = pavgvals\n",
      "        dfresults[metadata.name[i]+' PStdDEv'] = pstddevvals\n",
      "\n",
      "\n",
      "    if len(avgdata.shape) == 4:\n",
      "        for d in range(len(depthbins.index)):\n",
      "            avgvals = list()\n",
      "            stddevvals = list()\n",
      "            pavgvals = list()\n",
      "            pstddevvals = list()\n",
      "            count = list()\n",
      "            \n",
      "            for x in range(nsites):\n",
      "                \n",
      "                if (siteinfo.tested[x] == 'yes'):\n",
      "                    #mean of data(latitude_indices, longitude_indices)\n",
      "                    #The +1 is necessary because numpy indexing goes from start:end, but end is the first value that's NOT included.\n",
      "                    #Whereas the way I've set this up, the maxy and maxx SHOULD be included.\n",
      "                    count.append(ma.count(avgdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                              siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                              siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                    if (count[x] > 0):\n",
      "                        avgvals.append(ma.mean(avgdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                                                       siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                                                       siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                        stddevvals.append(ma.mean(stddevdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                                                             siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                                                             siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                        pavgvals.append(ma.mean(pavgdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                                                         siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                                                         siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                        pstddevvals.append(ma.mean(pstddevdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                                                               siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                                                               siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                    else:\n",
      "                        avgvals.append(np.nan)\n",
      "                        stddevvals.append(np.nan)\n",
      "                        pavgvals.append(np.nan)\n",
      "                        pstddevvals.append(np.nan)\n",
      "                else:\n",
      "                    avgvals.append(np.nan)\n",
      "                    stddevvals.append(np.nan)\n",
      "                    pavgvals.append(np.nan)\n",
      "                    pstddevvals.append(np.nan)\n",
      "                    count.append(np.nan)\n",
      "                    \n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' Count'] = count\n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' Avg' + ' in ' + metadata.units[i]] = avgvals\n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' StdDev' + ' in ' + metadata.units[i]] = stddevvals\n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' PAvg' + ' in ' + metadata.units[i]] = pavgvals\n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' PStdDEv' + ' in ' + metadata.units[i]] = pstddevvals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfresults.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Index: 5 entries, Jacksmith Bay to Cape Pierce to Homer Spit\n",
        "Columns: 180 entries, Ice Phytoplankton Concentration Count to Meridional (V) Current 75 to 200 m PStdDEv in m/s\n",
        "dtypes: float64(180)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 5 entries, Jacksmith Bay to Cape Pierce to Homer Spit\n",
        "Columns: 180 entries, Ice Phytoplankton Concentration Count to Meridional (V) Current 75 to 200 m PStdDEv in m/s\n",
        "dtypes: float64(180)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print siteinfo.iloc[2]\n",
      "dfresults.iloc[0,0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "id        audubon_ibas_v3_20aug2014.152\n",
        "minlat                         54.77736\n",
        "maxlat                         55.45225\n",
        "minlon                         199.7201\n",
        "maxlon                         201.0015\n",
        "miny                                 48\n",
        "maxy                                 54\n",
        "minx                                199\n",
        "maxx                                205\n",
        "tested                              yes\n",
        "Name: Shumagin Islands Marine, dtype: object\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "Ice Phytoplankton Concentration Count        39.000000\n",
        "Ice Phytoplankton Concentration Avg           0.631475\n",
        "Ice Phytoplankton Concentration StdDev        9.870099\n",
        "Ice Phytoplankton Concentration PAvg          0.485397\n",
        "Ice Phytoplankton Concentration PStdDEv      10.384192\n",
        "Benthos Concentration Count                  39.000000\n",
        "Benthos Concentration Avg                  4689.126633\n",
        "Benthos Concentration StdDev               2534.790162\n",
        "Benthos Concentration PAvg                 4020.149357\n",
        "Benthos Concentration PStdDEv              2025.374653\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Export to CSV\n",
      "Combine the siteinfo and dfresults dataframes, and write out to CSV."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged = siteinfo.join(dfresults, sort=False)\n",
      "merged.to_csv('statsIBAv3.csv', index_label='sitenum')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "siteinfo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Index: 208 entries, Jacksmith Bay to Cape Pierce to Whole Area\n",
        "Data columns (total 9 columns):\n",
        "minlat    208  non-null values\n",
        "maxlat    208  non-null values\n",
        "minlon    208  non-null values\n",
        "maxlon    208  non-null values\n",
        "miny      183  non-null values\n",
        "maxy      183  non-null values\n",
        "minx      164  non-null values\n",
        "maxx      164  non-null values\n",
        "tested    208  non-null values\n",
        "dtypes: float64(8), object(1)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 208 entries, Jacksmith Bay to Cape Pierce to Whole Area\n",
        "Data columns (total 9 columns):\n",
        "minlat    208  non-null values\n",
        "maxlat    208  non-null values\n",
        "minlon    208  non-null values\n",
        "maxlon    208  non-null values\n",
        "miny      183  non-null values\n",
        "maxy      183  non-null values\n",
        "minx      164  non-null values\n",
        "maxx      164  non-null values\n",
        "tested    208  non-null values\n",
        "dtypes: float64(8), object(1)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}