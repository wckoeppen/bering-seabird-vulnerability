# -*- coding: utf-8 -*-
# <nbformat>3.0</nbformat>

# <markdowncell>

# #Bering Seabirds
# Assessing the projected change in climate variability of areas used by seabirds in the Bering Sea.

# <codecell>

from utilities import css_styles
css_styles();

# <markdowncell>

# ####Load Important Bird Areas
# These are defined by [Audobon](http://web4.audubon.org/bird/iba/) and currently represent areas important for numerous species of birds. Single-species polygons are on the way.

# <codecell>

from owslib.wfs import WebFeatureService
known_wfs = "http://solo.axiomalaska.com/geoserver/audubon/ows"
wfs = WebFeatureService(known_wfs, version='1.0.0')
geojson_response = wfs.getfeature(typename=['audubon:audubon_ibas'], outputFormat="application/json", srsname="urn:x-ogc:def:crs:EPSG:4326").read()

# <codecell>

import json
from utilities import find_dict_keys

from shapely.geometry import shape, MultiPolygon

geojson = json.loads(geojson_response)    
geometries = find_dict_keys("geometry", geojson)
shapes = [shape(g) for g in geometries]

# <markdowncell>

# A utility to plot the imported IBAs as a reality check. (I'm curently ignoring the issue with the international date line, as it is only a display issue.)

# <codecell>

import folium
from utilities import get_coords

map_center = shapes[0].centroid
mapper = folium.Map(location=[65.1, -155.6], zoom_start=4)
for s in shapes:
    for c in get_coords(s):
        mapper.line(c, line_color='#FF0000', line_weight=5)
mapper.lat_lng_popover()
mapper._build_map()

from IPython.core.display import HTML
HTML('<iframe srcdoc="{srcdoc}" style="width: 100%; height: 535px; border: none"></iframe>'.format(srcdoc=mapper.HTML.replace('"', '&quot;')))

# <markdowncell>

# ### Set bbox filter
# For now, this just uses a manual box for one IBA in the Bering Sea. In the future, I'll try to (1) create boxes for each polygon automagically, (2) use the actual polygons. (It turns out that using polygon masks in the python numpy and panda libraries is not exactly straightfoward. So we will have to build a function to do that.)

# <codecell>

# miny, minx, maxy, maxx
minx = -174
miny = 61.38
maxx = -169.9
maxy = 63.17
analysis_box = miny, minx, maxy, maxx

from shapely.geometry import box
bound = box(*analysis_box).boundary.coords
mapper.line(bound, line_color='#0000FF', line_weight=5)
mapper._build_map()

# <codecell>

from IPython.core.display import HTML
HTML('<iframe srcdoc="{srcdoc}" style="width: 100%; height: 535px; border: none"></iframe>'.format(srcdoc=mapper.HTML.replace('"', '&quot;')))

# <markdowncell>

# ### Load model data
# In this (simple) example I'm using the [PMEL CCCma](http://portal.aoos.org/alaska-statewide.php#module-metadata/4f706756-7d57-11e3-bce5-00219bfe5678/a7b34348-8613-4006-99d8-37fd49812aaa), and just querying sea surface temperature. We're going to put a bunch of these together though. I'm finding the model URL using the [Axiom THREDDS catalog](http://thredds.axiomalaska.com/thredds/catalogs/aoos.html) of AOOS datasets.

# <markdowncell>

# ####Set Climate model(s) from which to pull data
# For some reason the CCCma model has a slightly different date range listed in the netCDF files. Not sure if this is real (i.e., they ran the model over a different time period) or a mistake in their documentation. These models are not tiny, so it can take a few seconds to access them.
# 
# [PMEL MIROC](http://portal.aoos.org/alaska-statewide.php#module-metadata/68ea728a-7d7a-11e3-823b-00219bfe5678/50242dc9-b639-42c4-8287-d0aeb082fb1f) - 12/29/2002 03:00 - 12/04/2039  
# [PMEL ECHO-G](http://portal.aoos.org/alaska-statewide.php#module-metadata/18ffa59c-7d7a-11e3-82a4-00219bfe5678/7bfa82c2-3051-484e-8c7b-9b9f711083f5) - 12/29/2002 03:00 - 12/04/2039  
# [PMEL CCCma](http://portal.aoos.org/alaska-statewide.php#module-metadata/4f706756-7d57-11e3-bce5-00219bfe5678/6b2d1f96-4c5b-4b13-ad57-c8ca2e326a34) - 01/26/2003 03:00 - 01/01/2040 

# <codecell>

# Global sea surface temperature - just as a test
#model = 'http://thredds.axiomalaska.com/thredds/dodsC/G1_SST.nc'
#standard_name = 'sea_surface_temperature'

#PMEL Models:
#model = 'http://thredds.axiomalaska.com/thredds/dodsC/PMEL_MIROC.nc' #MIROC
#model = 'http://thredds.axiomalaska.com/thredds/dodsC/PMEL_ECHOG.nc' #ECHO-G
model = 'http://thredds.axiomalaska.com/thredds/dodsC/PMEL_CCCMA1.nc' #CCCma

import netCDF4
nc = netCDF4.Dataset(model)

# <markdowncell>

# #### Set variable(s) from which to pull data
# Two of the variables just have surface values. Twelve others have depth as well. Are we only interested in the surface values?

# <codecell>

#Variables with time coordinates
#standard_name = 'ice_phytoplankton_concentration'
#standard_name = 'sea_ice_area_fraction'

#Variables with time and depth coordinates
#standard_name = 'benthos_concentration'
#standard_name = 'detritus_concentration'
#standard_name = 'euphausiids_concentration'
#standard_name = 'large_microzooplankton_concentration'
#standard_name = 'large_phytoplankton_concentration'
#standard_name = 'neocalanus_concentration'
#standard_name = 'offshore_neocalanus_concentration'
standard_name = 'sea_water_temperature'
#standard_name = 'small_coastal_copepod_concentration'
#standard_name = 'small_phytoplankton_concentration'
#standard_name = 'u_current' #Zonal Current 
#standard_name = 'v_current' #Meridional Current 

# <markdowncell>

# #### Pull in the variable we want to analyze

# <codecell>

from utilities import get_variable_from_standard
variable = get_variable_from_standard(nc, standard_name)[0]

# <codecell>

variable.shape

# <codecell>

variable.dimensions

# <markdowncell>

# #### Subset by bounding box

# <codecell>

import numpy as np

lat_var = get_variable_from_standard(nc, "latitude")[0]
lat_indexes = np.logical_and(lat_var[:] <= maxy,
                             lat_var[:] >= miny)
lat_indexes = np.where(lat_indexes)
lat_data = lat_var[lat_indexes]


lon_var = get_variable_from_standard(nc, "longitude")[0]
lon_indexes = np.logical_and(lon_var[:] <= maxx,
                             lon_var[:] >= minx)
lon_indexes = np.where(lon_indexes)
lon_data = lon_var[lon_indexes]

# <markdowncell>

# ### Set a time filter
# This is the time that we will search over in the model data. We'll eventually use this aggregate 

# <codecell>

min_time = "2010-01-01"  # UTC
max_time = "2013-01-01"  # UTC

import pytz
from dateutil.parser import parse
min_time = parse(min_time).replace(tzinfo=pytz.utc)
max_time = parse(max_time).replace(tzinfo=pytz.utc)

# <markdowncell>

# #### Subset by time
# In theory we should not need to set the time_var.units explicitly. Unfortunately PMEL used the unit string "sec since 1900-01-01" instead of "seconds since 1900-01-01", and the netCDF library only understands "days, hours, minutes, seconds, milliseconds or microseconds".

# <codecell>

import calendar
from datetime import datetime

time_var = get_variable_from_standard(nc, "time")[0]

if time_var.dtype == np.dtype('S1'):
    def str_to_epoch(date_str):
        return calendar.timegm(parse(date_str).replace(tzinfo=pytz.utc).timetuple())
    new_time = netCDF4.chartostring(time_var[:])
    
    #time_var.units = "seconds since 1970-01-01"
    new_min_time = calendar.timegm(min_time.timetuple())
    new_max_time = calendar.timegm(max_time.timetuple())
    np_str_to_epoch = np.vectorize(str_to_epoch)
    new_time = np_str_to_epoch(new_time)
    time_indexes = np.logical_and(new_time[:] <= new_max_time,
                                  new_time[:] >= new_min_time)
    time_indexes = np.where(time_indexes)
    time_data = new_time[time_indexes]
    time_data = netCDF4.num2date(time_data, time_var.units)
else:
    time_var.units = "seconds since 1900-01-01 00:00:00"
    new_min_time, new_max_time = netCDF4.date2num([min_time, max_time], time_var.units)
    time_indexes = np.logical_and(time_var[:] <= new_max_time,
                                  time_var[:] >= new_min_time)
    time_indexes = np.where(time_indexes)
    time_data = time_var[time_indexes]
    time_data = netCDF4.num2date(time_data, time_var.units)

# <markdowncell>

# #### Subset variable

# <codecell>

subset_variable = variable[time_indexes[0], lat_indexes[0], lon_indexes[0]]

# <codecell>

import pandas as pd
data = pd.Panel(subset_variable, items=time_data, major_axis=lat_data, minor_axis=lon_data)

# <codecell>

data

# <codecell>

data.to_frame().head(20)

# <codecell>


