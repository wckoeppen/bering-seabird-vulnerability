# -*- coding: utf-8 -*-
# <nbformat>3.0</nbformat>

# <codecell>

%matplotlib inline
import time
import numpy as np
from numpy import ma
import matplotlib.pyplot as plt
from matplotlib.ticker import NullFormatter
import netCDF4

from utilities import css_styles
css_styles()

# <codecell>

# Global sea surface temperature - just as a test
#model = 'http://thredds.axiomalaska.com/thredds/dodsC/G1_SST.nc'
#standard_name = 'sea_surface_temperature'

filecount = 1874.

#Get mean value
avg = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/Outputs/core_average.nc')
core_temp_avg = ma.masked_array(avg.variables['temp_latlon'][:])
mask=ma.getmask(core_temp_avg)

#Get Sum of squares by multiplying average square by number of counts
diff = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/Diff/core_diff_week1001.nc')
core_temp_diff = ma.masked_array(diff.variables['temp_latlon'][:], mask)

#Get Sum of squares by multiplying average square by number of counts
org = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/core_week1001.nc')
core_temp_org = ma.masked_array(org.variables['temp_latlon'][:], mask)

#Get mean value
avg = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/Outputs/cccma_average.nc')
cccma_temp_avg = ma.masked_array(avg.variables['temp_latlon'][:])
mask=ma.getmask(cccma_temp_avg)

#Get Sum of squares by multiplying average square by number of counts
diff = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/Diff/cccma_diff_week1001.nc')
cccma_temp_diff = ma.masked_array(diff.variables['temp_latlon'][:], mask)

#Get Sum of squares by multiplying average square by number of counts
org = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/cccma_week1001.nc')
cccma_temp_org = ma.masked_array(org.variables['temp_latlon'][:], mask)


vmin = -5.0
vmax = 10.0
cmap = 'autumn'
origin = 'lower'
interpolation = 'nearest'
orientation = 'vertical'
shrink = 0.8

#plt.figure(num=None, figsize=(16,10))
def create_subplot(data, ax=None):
    if ax is None:
        ax=plt.gca()
    im = ax.imshow(data, vmin=vmin, vmax=vmax,
                   origin='lower', interpolation='nearest', cmap = 'hot')
    return im

f, ax = plt.subplots(2,3, sharey=True, sharex=True, figsize = (16,10))
create_subplot(core_temp_avg[0,0])
create_subplot(core_temp_diff[0,0])
plt.show()



#colorbar(img, orientation='vertical', shrink=0.8)
#plt.show()

# <codecell>

figure(num=None, figsize=(16,5))
plot(variable[0,0,50,:], color='black', marker='o', markersize=4, markerfacecolor='red', markeredgewidth=1, label='Mean')
grid(True)
legend(loc=2, ncol=1, borderaxespad=0.5)
show()

# <markdowncell>

# ## Calculate Mapped Mean and Standard Deviations for baseline period
# We need to map the spatial variation of Bering-wide standard deviations away from Bering-wide mean.
# 
# 1. Calculate the latlon-dependent mean for each depth bin.
# 2. Calculate Bering-wide mean of variable across space, time and depth
# 3. Calculate Bering-wide standard deviation across space and time for each depth bin
# 4. Calculate ABS((latlon-dependent mean - Bering-wide mean)/(Bering-wide standard deviation))

# <markdowncell>

# ### Set a time filter
# This is the time that we will search over in the model data. We'll eventually use this aggregate 

# <codecell>

#Base Time Frame
base_starttime = '1970-01-01'
base_stoptime = '2000-12-31'

#Projected Time Frame
proj_starttime = '2010-01-01'  # UTC
proj_stoptime = '2010-12-01' # short time frame, just to test the system
#proj_stoptime = "2039-12-01"  # UTC - can't be 2040 because of the CCCma model

import pytz
from dateutil.parser import parse
min_time = parse(base_starttime).replace(tzinfo=pytz.utc)
max_time = parse(base_stoptime).replace(tzinfo=pytz.utc)

# <markdowncell>

# The following cell tries to match up the time filter (in UTC) to whatever the time units are in the model data (in this case listed in seconds).

# <codecell>

nc.variables['TIME'].standard_name

# <codecell>

import calendar
from datetime import datetime

time_var = nc.variables['TIME']
time_units = "seconds since 1900-01-01 00:00:00"
#time_var = get_variable_from_standard(nc, 'TIME')[0]

#The first part of this IF statement was because our test model (G1SST) had a bad time conversion.
#It may no longer be necessary (but keep the ELSE).
if time_var.dtype == np.dtype('S1'):
    def str_to_epoch(date_str):
        return calendar.timegm(parse(date_str).replace(tzinfo=pytz.utc).timetuple())
    new_time = netCDF4.chartostring(time_var[:])
    
    #time_var.units = "seconds since 1970-01-01"
    new_min_time = calendar.timegm(min_time.timetuple())
    new_max_time = calendar.timegm(max_time.timetuple())
    np_str_to_epoch = np.vectorize(str_to_epoch)
    new_time = np_str_to_epoch(new_time)
    time_indices = np.logical_and(new_time[:] <= new_max_time,
                                  new_time[:] >= new_min_time)
    time_indices = np.where(time_indices)
    time_data = new_time[time_indices]
    time_data = netCDF4.num2date(time_data, time_var.units)
else:
    new_min_time, new_max_time = netCDF4.date2num([min_time, max_time], time_units)
    time_indices = np.logical_and(time_var[:] <= new_max_time,
                                  time_var[:] >= new_min_time)
    time_indices = np.where(time_indices)
    time_data = time_var[time_indices]
#    time_data = netCDF4.num2date(time_data, time_units)

# <codecell>

print time_var.size

# <codecell>

print time_data.size

# <markdowncell>

# ### Set a Depth Filter
# We want a series of bins that go from 0-10; 10-60; and 60-200.

# <codecell>

minz = 0
maxz = 10

depth_var = get_variable_from_standard(nc, "depth")[0]
depth_indices = np.logical_and(depth_var[:] <= maxz,
                             depth_var[:] >= minz)
depth_indices = np.where(depth_indices)
depth_data = depth_var[depth_indices]

# <codecell>

print depth_data.size

# <markdowncell>

# ### Subset the Model Variable
# Print our previously found time, depth, latitude and longitude indices.

# <markdowncell>

# <div class='warning' ><strong>Memory errors</strong> - Running into some memory issues here because of the size of the array being called (the nc file with the models is 112018.0 Mbytes, or 112 Gb). In addition, the netCDF4 library doesn't like forking over this much data at once and gives a "Malformed or inacessible DAP DATADDS" error if the array has too many elements.</div>

# <markdowncell>

# This memory issue is impassible. Because we can't load in all the data at once, we need to do this via a loop. The [solution](http://stackoverflow.com/questions/10365119/mean-value-and-standard-deviation-of-a-very-huge-data-set) based on [rearrangement of the StdDeviation equation](http://www.derivations.org/stdev.pdf) is to only keep track of three numbers in actual memory:
# 
# 1. The sum of all values (sum_x)
# 2. The sum of their squares (sum_x2)
# 3. Total count of all values (n)
# 
# Mean = sum_x/n  
# Standard Deviation = (sum_x2 - (sum_x)<sup>2</sup>/n)/(n-1)

# <codecell>

print time_indices[0]
time_indices[0]
print depth_indices[0]
print variable.shape
print variable

# <markdowncell>

# Note: we have to be careful here because variable is a masked array. We only want to add to n the values that are unmasked (i.e., have data). Here I'm using the compressed() method, which loses the spatial component but returns just unmasked values .

# <markdowncell>

# <div class='warning'><strong>Takes a long time</strong> - Pulling 1 year of data for 3 depths for a single variable takes about 20 minutes. Estimating forward, 30 years of data will take around 10 hours.

# <codecell>

starttime = time.time()
sum_x = np.float64(0.)
sum_x2 = np.float64(0.)
n = np.int64(0)

print 'Start Time: ' + str(min_time)
print 'Stop Time: ' + str(max_time)

for t in time_indices[0]:
    for d in depth_indices[0]: # this is safety, in case the depth bin is very large
        flatslice=variable[t, d,:,:].compressed() # returns a 1D array of non-masked values
        sum_x = sum_x + np.sum(flatslice)
        sum_x2 = sum_x2 + np.sum(np.square(flatslice))
        n = n + flatslice.size
    print time_data[t-time_indices[0][0]]
    
marktime = time.time()-starttime
print 'Operation took ' + str(round(marktime/3600, 2)) + ' hours.'

# <codecell>

bw_mean = sum_x/n
bw_stddev = np.sqrt((sum_x2 - np.square(sum_x)/n)/(n-1))

print 'Bering-wide Mean:', bw_mean
print 'Bering-wide StdDev: ', bw_stddev

# <markdowncell>

# The following do mean and standard deviations over unique subsets too, but they generally suck up too much memory, and can't be called with too many time or depth indices. So I've commented them out for now.

# <rawcell>

# #subset = variable[time_indices[0], depth_indices[0], *, *]
# subset = variable[time_indices[0],depth_indices[0],:,:]
# #subset_variable = np.squeeze(subset_variable)
# print subset.shape

# <rawcell>

# starttime = time.time()
# mean = np.mean(variable, axes=(1,2))
# marktime = time.time()-starttime
# print str(marktime) + ' seconds'
# 
# stddev = np.std(variable, axes=(1,2))
# stoptime = time.time()-marktime
# print str(marktime) + ' seconds'

# <markdowncell>

# #### Subset model data by our bounding box
# Which will soon be a grouping of polygons.

# <codecell>

import numpy as np

lat_var = get_variable_from_standard(nc, "latitude")[0]
lat_indices = np.logical_and(lat_var[:] <= maxy,
                             lat_var[:] >= miny)
lat_indices = np.where(lat_indices)
lat_data = lat_var[lat_indices]


lon_var = get_variable_from_standard(nc, "longitude")[0]
#PMEL models are in positive east, so we have to convert our bounding box.
minx_modulo360 = minx + 360.
maxx_modulo360 = maxx + 360.

lon_indices = np.logical_and(lon_var[:] <= maxx_modulo360,
                             lon_var[:] >= minx_modulo360)

lon_indices = np.where(lon_indices)
lon_data = lon_var[lon_indices]

# <codecell>

import pandas as pd
data = pd.Panel(subset_variable, items=time_data, major_axis=lat_data, minor_axis=lon_data)

# <markdowncell>

# ##Plots
# Just a few quick plots to spur discussion.

# <markdowncell>

# ###Mean
# Currently set to be the mean value of the region of interest.

# <codecell>

figure(num=None, figsize=(16,5))
plot(time_data[0:150], means[0:150], color='black', marker='o', markersize=4, markerfacecolor='red', markeredgewidth=1, label='Mean')
ylabel(standard_name)
grid(True)
legend(loc=2, ncol=1, borderaxespad=0.5)
show()

# <codecell>

figure(num=None, figsize=(16,5))
plot(time_data, means, 'k', label='Mean')
xlabel('Year')
ylabel(standard_name)
legend(loc=2, ncol=1, borderaxespad=0.5)
grid(True)
show()

# <markdowncell>

# ###Standard Deviation
# This is currently the standard deviation across each time slice. That's not really what we want though. We want a sense of standard deviation over time.

# <codecell>

figure(num=None, figsize=(16,5))
plot(time_data[0:150], stddevs[0:150], color='blue', marker='o', markersize=4, markerfacecolor='blue', markeredgewidth=1, label='Std Dev')
ylabel(standard_name)
grid(True)
legend(loc=2, ncol=1, borderaxespad=0.5)
show()

# <codecell>

figure(num=None, figsize=(16,5))
plot(time_data, stddevs, 'b', label='Std Dev')
xlabel('Year')
ylabel(standard_name)
legend(loc=2, ncol=1, borderaxespad=0.5)
grid(True)
show()

# <codecell>


