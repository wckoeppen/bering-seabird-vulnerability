{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Subset higher order stats by our bounding boxes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#A list of imports we need for code later in the notebook.\n",
      "#The css_styles() function must go last.\n",
      "%matplotlib inline\n",
      "from owslib.wfs import WebFeatureService\n",
      "import json\n",
      "from utilities import find_dict_keys\n",
      "from shapely.geometry import shape, MultiPolygon\n",
      "from shapely.geometry import box\n",
      "\n",
      "import folium\n",
      "from utilities import get_coords\n",
      "from IPython.core.display import HTML\n",
      "\n",
      "import time\n",
      "import numpy as np\n",
      "from numpy import ma\n",
      "import netCDF4\n",
      "import pandas as pd\n",
      "from pandas import Series\n",
      "\n",
      "import matplotlib as mpl\n",
      "from matplotlib import cm\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib import ticker\n",
      "\n",
      "from utilities import css_styles\n",
      "css_styles()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <style>\n",
        "        .info {\n",
        "            background-color: #fcf8e3; border-color: #faebcc; border-left: 5px solid #8a6d3b; padding: 0.5em; color: #8a6d3b;\n",
        "        }\n",
        "        .success {\n",
        "            background-color: #d9edf7; border-color: #bce8f1; border-left: 5px solid #31708f; padding: 0.5em; color: #31708f;\n",
        "        }\n",
        "        .error {\n",
        "            background-color: #f2dede; border-color: #ebccd1; border-left: 5px solid #a94442; padding: 0.5em; color: #a94442;\n",
        "        }\n",
        "        .warning {\n",
        "            background-color: #fcf8e3; border-color: #faebcc; border-left: 5px solid #8a6d3b; padding: 0.5em; color: #8a6d3b;\n",
        "        }\n",
        "        </style>\n",
        "    "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x7f76181bbc90>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load our important bird areas again.\n",
      "known_wfs = \"http://solo.axiomalaska.com/geoserver/audubon/ows\"\n",
      "wfs = WebFeatureService(known_wfs, version='1.0.0')\n",
      "geojson_response = wfs.getfeature(typename=['audubon:audubon_ibas'], outputFormat=\"application/json\", srsname=\"urn:x-ogc:def:crs:EPSG:4326\").read()\n",
      "geojson = json.loads(geojson_response)\n",
      "\n",
      "geometries = find_dict_keys('geometry', geojson)\n",
      "shapes = [shape(g) for g in geometries]\n",
      "\n",
      "sitenums = find_dict_keys('sitenum', geojson)\n",
      "sitenums = [str(s) for s in sitenums]\n",
      "nsites=len(sitenums)\n",
      "\n",
      "objectids = find_dict_keys('objectid', geojson)\n",
      "objectids = [str(s) for s in objectids]\n",
      "\n",
      "#This generates bounding boxes from the complex geometries in shapes.\n",
      "minlat = list()\n",
      "minlon = list()\n",
      "maxlat = list()\n",
      "maxlon = list()\n",
      "for s in shapes:\n",
      "    minlat.append(s.bounds[0])\n",
      "    minlon.append(s.bounds[1])\n",
      "    maxlat.append(s.bounds[2])\n",
      "    maxlon.append(s.bounds[3])\n",
      "# miny, minx, maxy, maxx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Bring in netCDF datasets\n",
      "#Set datasets\n",
      "avg = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/Outputs/core_average.nc')\n",
      "stddev = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/Outputs/core_rmssdn.nc')\n",
      "pavg = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/Outputs/cccma_average.nc')\n",
      "pstddev = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/Outputs/cccma_rmssdn.nc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load latitude and longitude arrays\n",
      "latitude = np.array(avg.variables['LATITUDE'])\n",
      "longitude = np.array(avg.variables['LONGITUDE'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up depth bins, for these data, they are in meters\n",
      "\n",
      "depthbins = pd.DataFrame({'mindepth': [0, 10, 75],\n",
      "                          'maxdepth': [5, 60, 200]},\n",
      "                         index=['surface', 'midwater','deepwater'],\n",
      "                         columns=['mindepth', 'maxdepth', 'minz', 'maxz'])\n",
      "\n",
      "depth = np.array(avg.variables['zsalt'])\n",
      "depthindices=list()\n",
      "for d in range(len(depthbins.index)):\n",
      "    indicesz=np.where(np.logical_and(depth[:] <= depthbins.maxdepth[d],\n",
      "                                     depth[:] >= depthbins.mindepth[d]))\n",
      "    depthindices.append(indicesz[0])\n",
      "    if len(depthindices[d]) > 0:\n",
      "        depthbins.minz[d] = min(depthindices[d])\n",
      "        depthbins.maxz[d] = max(depthindices[d])\n",
      "        \n",
      "depthbins['label']=['0 to 5 m', '10 to 60 m', '75 to 200 m']\n",
      "        \n",
      "depthbins"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>mindepth</th>\n",
        "      <th>maxdepth</th>\n",
        "      <th>minz</th>\n",
        "      <th>maxz</th>\n",
        "      <th>label</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>surface</th>\n",
        "      <td>  0</td>\n",
        "      <td>   5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "      <td>    0 to 5 m</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>midwater</th>\n",
        "      <td> 10</td>\n",
        "      <td>  60</td>\n",
        "      <td> 2</td>\n",
        "      <td>  8</td>\n",
        "      <td>  10 to 60 m</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>deepwater</th>\n",
        "      <td> 75</td>\n",
        "      <td> 200</td>\n",
        "      <td> 9</td>\n",
        "      <td> 13</td>\n",
        "      <td> 75 to 200 m</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "           mindepth  maxdepth minz maxz        label\n",
        "surface           0         5    0    1     0 to 5 m\n",
        "midwater         10        60    2    8   10 to 60 m\n",
        "deepwater        75       200    9   13  75 to 200 m"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But each of these also need four slots for the [avg, stddev, pavg, pstddev]. I think it's best to create a new dataframe for each variable, test for depth, and if it has depth create the bins and add the columns to the individual dataframe. At the end, we can add all the dataframes together for output via a CSV.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This is our known metadata for the outputs\n",
      "metadata = pd.DataFrame({\n",
      "         'orgName': [\n",
      "                   #these don't have depth\n",
      "                   'icephl_latlon','ben_latlon',\n",
      "                   'aice_latlon',\n",
      "                   #these do\n",
      "                 'phs_latlon','phl_latlon','mzl_latlon','cop_latlon','ncao_latlon','ncas_latlon','eup_latlon','det_latlon',\n",
      "                 'temp_latlon',\n",
      "                 'u_latlon',\n",
      "                 'v_latlon',],\n",
      "         'name': ['Ice Phytoplankton Concentration',\n",
      "                  'Benthos Concentration',\n",
      "                  'Sea Ice Area Fraction',\n",
      "                  'Small Phytoplankton Concentration',\n",
      "                  'Large Phytoplankton Concentration',\n",
      "                  'Large Microzooplankton Concentration',\n",
      "                  'Small Coastal Copepod Concentration',\n",
      "                  'Offshore Neocalanus Concentration',\n",
      "                  'Neocalanus Concentration',\n",
      "                  'Euphausiids Concentration',\n",
      "                  'Detritus Concentration',\n",
      "                  'Sea Water Temperature',\n",
      "                  'Zonal (U) Current',\n",
      "                  'Meridional (V) Current'],\n",
      "         'units': ['mgC/m2','mgC/m2',\n",
      "                   'Fraction',\n",
      "                   'mgC/m3','mgC/m3','mgC/m3','mgC/m3','mgC/m3','mgC/m3','mgC/m3','mgC/m3',\n",
      "                   'degrees C',\n",
      "                   'm/s',\n",
      "                   'm/s']\n",
      "       })"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>orgName</th>\n",
        "      <th>units</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>   Ice Phytoplankton Concentration</td>\n",
        "      <td> icephl_latlon</td>\n",
        "      <td>   mgC/m2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>             Benthos Concentration</td>\n",
        "      <td>    ben_latlon</td>\n",
        "      <td>   mgC/m2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>             Sea Ice Area Fraction</td>\n",
        "      <td>   aice_latlon</td>\n",
        "      <td> Fraction</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Small Phytoplankton Concentration</td>\n",
        "      <td>    phs_latlon</td>\n",
        "      <td>   mgC/m3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Large Phytoplankton Concentration</td>\n",
        "      <td>    phl_latlon</td>\n",
        "      <td>   mgC/m3</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                                name        orgName     units\n",
        "0    Ice Phytoplankton Concentration  icephl_latlon    mgC/m2\n",
        "1              Benthos Concentration     ben_latlon    mgC/m2\n",
        "2              Sea Ice Area Fraction    aice_latlon  Fraction\n",
        "3  Small Phytoplankton Concentration     phs_latlon    mgC/m3\n",
        "4  Large Phytoplankton Concentration     phl_latlon    mgC/m3"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some shapes will be empty (i.e., there's a polygon, but no model data), others will have very few values. We should keep track of how many model pixels are going into each resulting mean. For the combined IBAs, there are 210 polygons, identified by sitenums, objectids, and their geometries.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Store the results by keeping track of the data in a Panda Dataframes\n",
      "We will append columns to these and fill in the data as we get it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create a dataframe to house the IBA site information, indexed by the IBA sitenums.\n",
      "siteinfo = pd.DataFrame(\n",
      "                        {\n",
      "                        'objectid': objectids,\n",
      "                        'minlat': minlat,\n",
      "                        'minlon': minlon,\n",
      "                        'maxlat': maxlat,\n",
      "                        'maxlon': maxlon,\n",
      "                        'tested': (['no'] * nsites)\n",
      "                        },\n",
      "                        index = sitenums,\n",
      "                        columns = ['objectid', 'minlat', 'maxlat', 'minlon', 'maxlon',\n",
      "                                  'miny', 'maxy', 'minx', 'maxx','tested']\n",
      "                       )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now convert the latlons to pixel indices for the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latindices = list()\n",
      "lonindices = list()\n",
      "\n",
      "for x in range(nsites):\n",
      "    #first do latitude\n",
      "    indicesy = np.where(np.logical_and(latitude <= maxlat[x],\n",
      "                                       latitude >= minlat[x]))\n",
      "    latindices.append(indicesy[0])\n",
      "    #then longitude\n",
      "    #PMEL models are in positive east, so we have to convert our bounding box.\n",
      "    indicesx = np.where(np.logical_and(longitude[:] <= maxlon[x]+360,\n",
      "                                       longitude[:] >= minlon[x]+360))\n",
      "    lonindices.append(indicesx[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#finds the minimum and maxium pixel indices for each sitenum\n",
      "avgdata = ma.masked_array(avg.variables[metadata.orgName[0]][:])\n",
      "for x in range(nsites-1):\n",
      "    if len(latindices[x]) > 0:\n",
      "        siteinfo.miny[x] = min(latindices[x])\n",
      "        siteinfo.maxy[x] = max(latindices[x])\n",
      "    if len(lonindices[x]) > 0:\n",
      "        siteinfo.minx[x] = min(lonindices[x])\n",
      "        siteinfo.maxx[x] = max(lonindices[x]) \n",
      "#This tests to see if there are any NaNs, meaning the IBA goes off the edge of the model.\n",
      "#We'll skip any of those IBAs by setting a \"Tested\" variable to 0.\n",
      "    if pd.notnull(siteinfo.miny[x]):\n",
      "        if pd.notnull(siteinfo.maxy[x]):\n",
      "            if pd.notnull(siteinfo.minx[x]):\n",
      "                if pd.notnull(siteinfo.maxx[x]):\n",
      "                    #This will find if there are any non-masked values to test.\n",
      "                    count = ma.count(avgdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1])\n",
      "                    if count > 0:\n",
      "                        siteinfo.tested[x] = 'yes'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "siteinfo.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>objectid</th>\n",
        "      <th>minlat</th>\n",
        "      <th>maxlat</th>\n",
        "      <th>minlon</th>\n",
        "      <th>maxlon</th>\n",
        "      <th>miny</th>\n",
        "      <th>maxy</th>\n",
        "      <th>minx</th>\n",
        "      <th>maxx</th>\n",
        "      <th>tested</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>994</th>\n",
        "      <td>  1</td>\n",
        "      <td> 67.041722</td>\n",
        "      <td> 67.230738</td>\n",
        "      <td>-163.853365</td>\n",
        "      <td>-163.312672</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 181</td>\n",
        "      <td> 183</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1021</th>\n",
        "      <td>  2</td>\n",
        "      <td> 66.475266</td>\n",
        "      <td> 66.625279</td>\n",
        "      <td>-164.010682</td>\n",
        "      <td>-163.456896</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 180</td>\n",
        "      <td> 182</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1022</th>\n",
        "      <td>  3</td>\n",
        "      <td> 65.822087</td>\n",
        "      <td> 66.568809</td>\n",
        "      <td>-167.411918</td>\n",
        "      <td>-164.616052</td>\n",
        "      <td> 159</td>\n",
        "      <td> 160</td>\n",
        "      <td> 163</td>\n",
        "      <td> 176</td>\n",
        "      <td> yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1020</th>\n",
        "      <td>  4</td>\n",
        "      <td> 66.120101</td>\n",
        "      <td> 66.261479</td>\n",
        "      <td>-164.546729</td>\n",
        "      <td>-163.858311</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 178</td>\n",
        "      <td> 180</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1004</th>\n",
        "      <td> 56</td>\n",
        "      <td> 61.051306</td>\n",
        "      <td> 61.229063</td>\n",
        "      <td>-150.126832</td>\n",
        "      <td>-149.793940</td>\n",
        "      <td> 111</td>\n",
        "      <td> 112</td>\n",
        "      <td> 250</td>\n",
        "      <td> 250</td>\n",
        "      <td> yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1082</th>\n",
        "      <td> 57</td>\n",
        "      <td> 61.049059</td>\n",
        "      <td> 61.192381</td>\n",
        "      <td>-149.992403</td>\n",
        "      <td>-149.494204</td>\n",
        "      <td> 111</td>\n",
        "      <td> 111</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1023</th>\n",
        "      <td>  5</td>\n",
        "      <td> 65.356310</td>\n",
        "      <td> 65.967801</td>\n",
        "      <td>-166.409767</td>\n",
        "      <td>-164.296922</td>\n",
        "      <td> 154</td>\n",
        "      <td> 159</td>\n",
        "      <td> 168</td>\n",
        "      <td> 178</td>\n",
        "      <td>  no</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1024</th>\n",
        "      <td>  6</td>\n",
        "      <td> 65.565299</td>\n",
        "      <td> 65.836834</td>\n",
        "      <td>-168.174747</td>\n",
        "      <td>-167.419334</td>\n",
        "      <td> 156</td>\n",
        "      <td> 158</td>\n",
        "      <td> 160</td>\n",
        "      <td> 162</td>\n",
        "      <td> yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1029</th>\n",
        "      <td>  7</td>\n",
        "      <td> 64.464191</td>\n",
        "      <td> 64.947592</td>\n",
        "      <td>-161.294254</td>\n",
        "      <td>-160.722232</td>\n",
        "      <td> 145</td>\n",
        "      <td> 149</td>\n",
        "      <td> 194</td>\n",
        "      <td> 196</td>\n",
        "      <td> yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2923</th>\n",
        "      <td> 58</td>\n",
        "      <td> 57.591365</td>\n",
        "      <td> 57.822797</td>\n",
        "      <td>-152.573709</td>\n",
        "      <td>-152.070560</td>\n",
        "      <td>  76</td>\n",
        "      <td>  78</td>\n",
        "      <td> 238</td>\n",
        "      <td> 239</td>\n",
        "      <td> yes</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "     objectid     minlat     maxlat      minlon      maxlon miny maxy minx  \\\n",
        "994         1  67.041722  67.230738 -163.853365 -163.312672  NaN  NaN  181   \n",
        "1021        2  66.475266  66.625279 -164.010682 -163.456896  NaN  NaN  180   \n",
        "1022        3  65.822087  66.568809 -167.411918 -164.616052  159  160  163   \n",
        "1020        4  66.120101  66.261479 -164.546729 -163.858311  NaN  NaN  178   \n",
        "1004       56  61.051306  61.229063 -150.126832 -149.793940  111  112  250   \n",
        "1082       57  61.049059  61.192381 -149.992403 -149.494204  111  111  NaN   \n",
        "1023        5  65.356310  65.967801 -166.409767 -164.296922  154  159  168   \n",
        "1024        6  65.565299  65.836834 -168.174747 -167.419334  156  158  160   \n",
        "1029        7  64.464191  64.947592 -161.294254 -160.722232  145  149  194   \n",
        "2923       58  57.591365  57.822797 -152.573709 -152.070560   76   78  238   \n",
        "\n",
        "     maxx tested  \n",
        "994   183     no  \n",
        "1021  182     no  \n",
        "1022  176    yes  \n",
        "1020  180     no  \n",
        "1004  250    yes  \n",
        "1082  NaN     no  \n",
        "1023  178     no  \n",
        "1024  162    yes  \n",
        "1029  196    yes  \n",
        "2923  239    yes  "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Process the data into a list of dataframes, indexed by sitenum"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have the pixel mins and maxes, we can iterate through the variables:\n",
      "\n",
      "1. Check for depth: if present iterate three times for depth bins, if absent, just do once.  \n",
      "2. Using the pixel indexes to subset each model variable for avg, stddev, pavg, and pstddev arrays and average those values.  \n",
      "3. Create a data frame with the mean avg, stddev, pavg, and pstddev for each sitenum, and append to list of dataframe results\n",
      "4. Create a label including the variable name and depth bin, append to another list of results. There should be one label for each dataframe.\n",
      "5. We'll concatenate these dataframes to the siteinfo dataframe into large dataframe for output to CSV."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nvariables = len(metadata.orgName)\n",
      "#create an empty dataframe\n",
      "dfresults = pd.DataFrame(index = sitenums)\n",
      "\n",
      "#for each variable\n",
      "for i in range(nvariables): \n",
      "    #Load in the data\n",
      "    avgdata = ma.masked_array(avg.variables[metadata.orgName[i]][:])\n",
      "    mask=ma.getmask(avgdata)\n",
      "    stddevdata = ma.masked_array(stddev.variables[metadata.orgName[i]][:], mask)\n",
      "    pavgdata = ma.masked_array(pavg.variables[metadata.orgName[i]][:], mask)\n",
      "    pstddevdata = ma.masked_array(pstddev.variables[metadata.orgName[i]][:], mask)\n",
      "    \n",
      "    #check for depth\n",
      "    if len(avgdata.shape) == 3:\n",
      "        avgvals = list()\n",
      "        stddevvals = list()\n",
      "        pavgvals = list()\n",
      "        pstddevvals = list()\n",
      "        count = list()\n",
      "        \n",
      "        for x in range(nsites):\n",
      "            if (siteinfo.tested[x] == 'yes'):\n",
      "                #mean of data(latitude_indices, longitude_indices)\n",
      "                #The +1 is necessary because numpy indexing goes from start:end, but end is the first value that's NOT included.\n",
      "                #Whereas the way I've set this up, the maxy and maxx SHOULD be included.\n",
      "                avgvals.append(ma.mean(avgdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                stddevvals.append(ma.mean(stddevdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                pavgvals.append(ma.mean(pavgdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                pstddevvals.append(ma.mean(pstddevdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                count.append(ma.count(avgdata[0, siteinfo.miny[x]:siteinfo.maxy[x]+1, siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "\n",
      "            else:\n",
      "                avgvals.append(np.nan)\n",
      "                stddevvals.append(np.nan)\n",
      "                pavgvals.append(np.nan)\n",
      "                pstddevvals.append(np.nan)\n",
      "                count.append(np.nan)\n",
      "        \n",
      "        dfresults[metadata.name[i]+' Count'] = count\n",
      "        dfresults[metadata.name[i]+' Avg'] = avgvals\n",
      "        dfresults[metadata.name[i]+' StdDev'] = stddevvals\n",
      "        dfresults[metadata.name[i]+' PAvg'] = pavgvals\n",
      "        dfresults[metadata.name[i]+' PStdDEv'] = pstddevvals\n",
      "\n",
      "\n",
      "    if len(avgdata.shape) == 4:\n",
      "        for d in range(len(depthbins.index)):\n",
      "            avgvals = list()\n",
      "            stddevvals = list()\n",
      "            pavgvals = list()\n",
      "            pstddevvals = list()\n",
      "            count = list()\n",
      "            \n",
      "            for x in range(nsites):\n",
      "                \n",
      "                if (siteinfo.tested[x] == 'yes'):\n",
      "                    #mean of data(latitude_indices, longitude_indices)\n",
      "                    #The +1 is necessary because numpy indexing goes from start:end, but end is the first value that's NOT included.\n",
      "                    #Whereas the way I've set this up, the maxy and maxx SHOULD be included.\n",
      "                    count.append(ma.count(avgdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                              siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                              siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                    if (count[x] > 0):\n",
      "                        avgvals.append(ma.mean(avgdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                                                       siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                                                       siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                        stddevvals.append(ma.mean(stddevdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                                                             siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                                                             siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                        pavgvals.append(ma.mean(pavgdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                                                         siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                                                         siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                        pstddevvals.append(ma.mean(pstddevdata[0, depthbins.minz[d]:depthbins.maxz[d]+1,\n",
      "                                                               siteinfo.miny[x]:siteinfo.maxy[x]+1,\n",
      "                                                               siteinfo.minx[x]:siteinfo.maxx[x]+1]))\n",
      "                    else:\n",
      "                        avgvals.append(np.nan)\n",
      "                        stddevvals.append(np.nan)\n",
      "                        pavgvals.append(np.nan)\n",
      "                        pstddevvals.append(np.nan)\n",
      "                else:\n",
      "                    avgvals.append(np.nan)\n",
      "                    stddevvals.append(np.nan)\n",
      "                    pavgvals.append(np.nan)\n",
      "                    pstddevvals.append(np.nan)\n",
      "                    count.append(np.nan)\n",
      "                    \n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' Count'] = count\n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' Avg' + ' in ' + metadata.units[i]] = avgvals\n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' StdDev' + ' in ' + metadata.units[i]] = stddevvals\n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' PAvg' + ' in ' + metadata.units[i]] = pavgvals\n",
      "            dfresults[metadata.name[i]+' '+depthbins.label[d]+' PStdDEv' + ' in ' + metadata.units[i]] = pstddevvals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfresults.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Index: 5 entries, 994 to 1004\n",
        "Columns: 180 entries, Ice Phytoplankton Concentration Count to Meridional (V) Current 75 to 200 m PStdDEv in m/s\n",
        "dtypes: float64(180)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 5 entries, 994 to 1004\n",
        "Columns: 180 entries, Ice Phytoplankton Concentration Count to Meridional (V) Current 75 to 200 m PStdDEv in m/s\n",
        "dtypes: float64(180)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print siteinfo.iloc[8]\n",
      "dfresults.iloc[8,130:150]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "objectid           7\n",
        "minlat      64.46419\n",
        "maxlat      64.94759\n",
        "minlon     -161.2943\n",
        "maxlon     -160.7222\n",
        "miny             145\n",
        "maxy             149\n",
        "minx             194\n",
        "maxx             196\n",
        "tested           yes\n",
        "Name: 1029, dtype: object\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "Detritus Concentration 75 to 200 m Count                   0.000000\n",
        "Detritus Concentration 75 to 200 m Avg in mgC/m3                NaN\n",
        "Detritus Concentration 75 to 200 m StdDev in mgC/m3             NaN\n",
        "Detritus Concentration 75 to 200 m PAvg in mgC/m3               NaN\n",
        "Detritus Concentration 75 to 200 m PStdDEv in mgC/m3            NaN\n",
        "Sea Water Temperature 0 to 5 m Count                      20.000000\n",
        "Sea Water Temperature 0 to 5 m Avg in degrees C            2.078602\n",
        "Sea Water Temperature 0 to 5 m StdDev in degrees C         5.562691\n",
        "Sea Water Temperature 0 to 5 m PAvg in degrees C           1.045532\n",
        "Sea Water Temperature 0 to 5 m PStdDEv in degrees C        4.455698\n",
        "Sea Water Temperature 10 to 60 m Count                    10.000000\n",
        "Sea Water Temperature 10 to 60 m Avg in degrees C          2.078602\n",
        "Sea Water Temperature 10 to 60 m StdDev in degrees C       5.562691\n",
        "Sea Water Temperature 10 to 60 m PAvg in degrees C         1.045532\n",
        "Sea Water Temperature 10 to 60 m PStdDEv in degrees C      4.455698\n",
        "Sea Water Temperature 75 to 200 m Count                    0.000000\n",
        "Sea Water Temperature 75 to 200 m Avg in degrees C              NaN\n",
        "Sea Water Temperature 75 to 200 m StdDev in degrees C           NaN\n",
        "Sea Water Temperature 75 to 200 m PAvg in degrees C             NaN\n",
        "Sea Water Temperature 75 to 200 m PStdDEv in degrees C          NaN\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Export to CSV\n",
      "Combine the siteinfo and dfresults dataframes, and write out to CSV."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged = siteinfo.join(dfresults)\n",
      "merged.to_csv('allspeciesIBAs.csv', index_label='sitenum')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    }
   ],
   "metadata": {}
  }
 ]
}