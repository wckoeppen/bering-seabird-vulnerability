{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Calculate Higher Level Statistics\n",
      "This notbook uses [base statistics](calculate_base_stats.ipynb) to calculate higher order stats to assess Seabird Vulnerability in the Bering Sea"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#A list of imports we need for code later in the notebook.\n",
      "#The css_styles() function must go last.\n",
      "%matplotlib inline\n",
      "from owslib.wfs import WebFeatureService\n",
      "import json\n",
      "from utilities import find_dict_keys\n",
      "from shapely.geometry import shape, MultiPolygon\n",
      "from shapely.geometry import box\n",
      "\n",
      "import folium\n",
      "from utilities import get_coords\n",
      "from IPython.core.display import HTML\n",
      "\n",
      "import time\n",
      "import numpy as np\n",
      "from numpy import ma\n",
      "import netCDF4\n",
      "\n",
      "import calendar\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib as mpl\n",
      "from matplotlib import cm\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib import ticker\n",
      "\n",
      "from utilities import css_styles\n",
      "css_styles()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <style>\n",
        "        .info {\n",
        "            background-color: #fcf8e3; border-color: #faebcc; border-left: 5px solid #8a6d3b; padding: 0.5em; color: #8a6d3b;\n",
        "        }\n",
        "        .success {\n",
        "            background-color: #d9edf7; border-color: #bce8f1; border-left: 5px solid #31708f; padding: 0.5em; color: #31708f;\n",
        "        }\n",
        "        .error {\n",
        "            background-color: #f2dede; border-color: #ebccd1; border-left: 5px solid #a94442; padding: 0.5em; color: #a94442;\n",
        "        }\n",
        "        .warning {\n",
        "            background-color: #fcf8e3; border-color: #faebcc; border-left: 5px solid #8a6d3b; padding: 0.5em; color: #8a6d3b;\n",
        "        }\n",
        "        </style>\n",
        "    "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<IPython.core.display.HTML at 0x7f9270122950>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Variable Names\n",
      "Because we're accessing raw NetCDF files instead of aggregated and curated NcML, we need to access the data using the original variable names."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Variables with time and depth coordinates\n",
      "#biological\n",
      "variable_index = 10\n",
      "\n",
      "original_names=['icephl_latlon',\n",
      "                'phs_latlon',\n",
      "                'phl_latlon',\n",
      "                'mzl_latlon',\n",
      "                'cop_latlon',\n",
      "                'ncao_latlon',\n",
      "                'ncas_latlon',\n",
      "                'eup_latlon',\n",
      "                'det_latlon',\n",
      "                'ben_latlon',\n",
      "                'temp_latlon',\n",
      "                'aice_latlon',\n",
      "                'u_latlon',\n",
      "                'v_latlon'\n",
      "                ]\n",
      "\n",
      "standard_names=[\n",
      "                'ice_phytoplankton_concentration', #(no depth)\n",
      "                'small_phytoplankton_concentration',\n",
      "                'large_phytoplankton_concentration',\n",
      "                'large_microzooplankton_concentration',\n",
      "                'small_coastal_copepod_concentration',\n",
      "                'offshore_neocalanus_concentration',\n",
      "                'neocalanus_concentration',\n",
      "                'euphausiids_concentration',\n",
      "                'detritus_concentration',\n",
      "                'benthos_concentration', #benthic infauna\n",
      "                'sea_water_temperature',\n",
      "                'salinity',\n",
      "                'sea_ice_area_fraction',\n",
      "                'u_current', #Zonal Current \n",
      "                'v_current' #Meridional Current\n",
      "                ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'sea_water_temperature'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Global sea surface temperature - just as a test\n",
      "#model = 'http://thredds.axiomalaska.com/thredds/dodsC/G1_SST.nc'\n",
      "#standard_name = 'sea_surface_temperature'\n",
      "\n",
      "#Hindcast\n",
      "#Get mean value\n",
      "nc = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/Outputs/core_average.nc')\n",
      "core_temp_avg = ma.masked_array(avg.variables['temp_latlon'][:])\n",
      "mask=ma.getmask(core_temp_avg)\n",
      "\n",
      "#Get Sum of squares by multiplying average square by number of counts\n",
      "stddev = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/core/Outputs/core_rmssdn.nc')\n",
      "core_temp_stddev = ma.masked_array(stddev.variables['temp_latlon'][:], mask)\n",
      "\n",
      "#Projected\n",
      "#Get mean value\n",
      "pavg = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/Outputs/cccma_average.nc')\n",
      "cccma_temp_avg = ma.masked_array(pavg.variables['temp_latlon'][:])\n",
      "\n",
      "#Get Sum of squares by multiplying average square by number of counts\n",
      "pstddev = netCDF4.Dataset('/augie/gluster/data/netCDF/pmel/cccma/Outputs/cccma_rmssdn.nc')\n",
      "cccma_temp_stddev = ma.masked_array(pstddev.variables['temp_latlon'][:], mask)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "standard_names[variable_index]\n",
      "variable = nc.variables[original_names[variable_index]]\n",
      "\n",
      "#from utilities import get_variable_from_standard\n",
      "#variable = get_variable_from_standard(nc, standard_names[variable_index])[0]\n",
      "\n",
      "print variable.dimensions\n",
      "print variable.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'TIME', u'zsalt', u'LATITUDE', u'LONGITUDE')\n",
        "(1, 16, 161, 251)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Set a time filter\n",
      "This is the time that we will search over in the model data. We'll eventually use this aggregate "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Base Time Frame\n",
      "base_starttime = '1970-01-01'\n",
      "base_stoptime = '2000-12-31'\n",
      "\n",
      "#Projected Time Frame\n",
      "proj_starttime = '2010-01-01'  # UTC\n",
      "proj_stoptime = '2010-12-01' # short time frame, just to test the system\n",
      "#proj_stoptime = \"2039-12-01\"  # UTC - can't be 2040 because of the CCCma model\n",
      "\n",
      "import pytz\n",
      "from dateutil.parser import parse\n",
      "min_time = parse(base_starttime).replace(tzinfo=pytz.utc)\n",
      "max_time = parse(base_stoptime).replace(tzinfo=pytz.utc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following cell tries to match up the time filter (in UTC) to whatever the time units are in the model data (in this case listed in seconds)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_var = nc.variables['TIME']\n",
      "time_units = \"seconds since 1900-01-01 00:00:00\"\n",
      "#time_var = get_variable_from_standard(nc, 'TIME')[0]\n",
      "\n",
      "#The first part of this IF statement was because our test model (G1SST) had a bad time conversion.\n",
      "#It may no longer be necessary (but keep the ELSE).\n",
      "if time_var.dtype == np.dtype('S1'):\n",
      "    def str_to_epoch(date_str):\n",
      "        return calendar.timegm(parse(date_str).replace(tzinfo=pytz.utc).timetuple())\n",
      "    new_time = netCDF4.chartostring(time_var[:])\n",
      "    \n",
      "    #time_var.units = \"seconds since 1970-01-01\"\n",
      "    new_min_time = calendar.timegm(min_time.timetuple())\n",
      "    new_max_time = calendar.timegm(max_time.timetuple())\n",
      "    np_str_to_epoch = np.vectorize(str_to_epoch)\n",
      "    new_time = np_str_to_epoch(new_time)\n",
      "    time_indices = np.logical_and(new_time[:] <= new_max_time,\n",
      "                                  new_time[:] >= new_min_time)\n",
      "    time_indices = np.where(time_indices)\n",
      "    time_data = new_time[time_indices]\n",
      "    time_data = netCDF4.num2date(time_data, time_var.units)\n",
      "else:\n",
      "    new_min_time, new_max_time = netCDF4.date2num([min_time, max_time], time_units)\n",
      "    time_indices = np.logical_and(time_var[:] <= new_max_time,\n",
      "                                  time_var[:] >= new_min_time)\n",
      "    time_indices = np.where(time_indices)\n",
      "    time_data = time_var[time_indices]\n",
      "#    time_data = netCDF4.num2date(time_data, time_units)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Set a Depth Filter\n",
      "We want a series of bins that go from 0-10; 10-60; and 60-200."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minz = 0\n",
      "maxz = 10\n",
      "\n",
      "depth_var = get_variable_from_standard(nc, \"depth\")[0]\n",
      "depth_indices = np.logical_and(depth_var[:] <= maxz,\n",
      "                             depth_var[:] >= minz)\n",
      "depth_indices = np.where(depth_indices)\n",
      "depth_data = depth_var[depth_indices]\n",
      "\n",
      "print depth_data.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'get_variable_from_standard' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-10-90c09277992c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmaxz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdepth_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_variable_from_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"depth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m depth_indices = np.logical_and(depth_var[:] <= maxz,\n\u001b[0;32m      6\u001b[0m                              depth_var[:] >= minz)\n",
        "\u001b[1;31mNameError\u001b[0m: name 'get_variable_from_standard' is not defined"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Subset the Model Variable\n",
      "Print our previously found time, depth, latitude and longitude indices. Note: we have to be careful here because variable is a masked array. We only want to add to n the values that are unmasked (i.e., have data). Here I'm using the compressed() method, which loses the spatial component but returns just unmasked values ."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print time_indices[0]\n",
      "time_indices[0]\n",
      "print depth_indices[0]\n",
      "print variable.shape\n",
      "print variable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "starttime = time.time()\n",
      "sum_x = np.float64(0.)\n",
      "sum_x2 = np.float64(0.)\n",
      "n = np.int64(0)\n",
      "\n",
      "print 'Start Time: ' + str(min_time)\n",
      "print 'Stop Time: ' + str(max_time)\n",
      "\n",
      "for t in time_indices[0]:\n",
      "    for d in depth_indices[0]: # this is safety, in case the depth bin is very large\n",
      "        flatslice=variable[t, d,:,:].compressed() # returns a 1D array of non-masked values\n",
      "        sum_x = sum_x + np.sum(flatslice)\n",
      "        sum_x2 = sum_x2 + np.sum(np.square(flatslice))\n",
      "        n = n + flatslice.size\n",
      "    print time_data[t-time_indices[0][0]]\n",
      "    \n",
      "marktime = time.time()-starttime\n",
      "print 'Operation took ' + str(round(marktime/3600, 2)) + ' hours.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}